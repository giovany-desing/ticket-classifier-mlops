"""
Schemas Pydantic para validaci√≥n de configuraci√≥n.

Valida config.yaml al cargar, asegurando tipos correctos y valores v√°lidos.

Autor: Sistema MLOps
Fecha: 2024
"""

from pydantic import BaseModel, Field, validator, ValidationError
from typing import List, Optional
import logging
import re

logger = logging.getLogger(__name__)


class DataConfig(BaseModel):
    """Configuraci√≥n de datos"""
    raw_path: str = Field(..., description="Path al directorio de datos raw")
    dataset_name: str = Field(..., description="Nombre del archivo de dataset")
    target_col: str = Field(..., description="Nombre de la columna objetivo")
    
    @validator('raw_path')
    def validate_raw_path(cls, v):
        if not v or len(v.strip()) == 0:
            raise ValueError("raw_path no puede estar vac√≠o")
        return v.strip()


class MLflowTrackingConfig(BaseModel):
    """Configuraci√≥n de MLflow"""
    experiment_name: str = Field(..., description="Nombre del experimento MLflow")
    
    @validator('experiment_name')
    def validate_experiment_name(cls, v):
        if not v or len(v.strip()) == 0:
            raise ValueError("experiment_name no puede estar vac√≠o")
        return v.strip()


class PreprocessingConfig(BaseModel):
    """Configuraci√≥n de preprocesamiento"""
    custom_stopwords: List[str] = Field(default_factory=list, description="Stopwords personalizadas")
    language: str = Field(default="spanish", description="Idioma para stemming")
    apply_stemming: bool = Field(default=True, description="Aplicar stemming")
    
    @validator('language')
    def validate_language(cls, v):
        valid_languages = ['spanish', 'english', 'portuguese', 'french', 'german']
        if v.lower() not in valid_languages:
            raise ValueError(f"language debe ser uno de: {valid_languages}")
        return v.lower()


class MonitoringConfig(BaseModel):
    """Configuraci√≥n de monitoreo"""
    drift_threshold: float = Field(default=0.05, ge=0, le=1, description="Umbral de drift (p-value)")
    drift_score_threshold: float = Field(default=0.5, ge=0, le=1, description="Score de drift para reentrenamiento")
    min_predictions_for_drift: int = Field(default=100, ge=1, description="M√≠nimo de predicciones para analizar drift")
    performance_drop_threshold: float = Field(default=0.05, ge=0, le=1, description="Ca√≠da de performance para trigger")
    
    min_labeled_predictions: int = Field(default=50, ge=1, description="M√≠nimo de predicciones etiquetadas")
    evaluation_window_hours: int = Field(default=48, ge=1, description="Ventana de tiempo para evaluaci√≥n")
    
    retrain_on_drift: bool = Field(default=True, description="Reentrenar autom√°ticamente si hay drift")
    retrain_on_performance_drop: bool = Field(default=True, description="Reentrenar si performance baja")
    min_improvement_for_deploy: float = Field(default=0.01, ge=0, le=1, description="Mejora m√≠nima para deploy")
    
    @validator('drift_threshold', 'performance_drop_threshold', 'min_improvement_for_deploy')
    def validate_threshold_range(cls, v, field):
        if not 0 <= v <= 1:
            raise ValueError(f"{field.name} debe estar entre 0 y 1, recibido: {v}")
        return v


class ThresholdsConfig(BaseModel):
    """Configuraci√≥n de umbrales avanzados"""
    # Drift detection
    drift_score_threshold: float = Field(default=0.5, ge=0, le=1)
    ks_test_threshold: float = Field(default=0.05, ge=0, le=1)
    chi2_test_threshold: float = Field(default=0.05, ge=0, le=1)
    vocab_growth_threshold: float = Field(default=1.2, ge=1.0)
    
    # Performance
    f1_score_minimum: float = Field(default=0.85, ge=0, le=1)
    performance_drop_threshold: float = Field(default=0.05, ge=0, le=1)
    min_improvement_for_deploy: float = Field(default=0.01, ge=0, le=1)
    
    # Confidence
    low_confidence_threshold: float = Field(default=0.6, ge=0, le=1)
    low_confidence_ratio_max: float = Field(default=0.3, ge=0, le=1)
    
    # Data requirements
    min_samples_training: int = Field(default=100, ge=1)
    min_predictions_for_drift: int = Field(default=50, ge=1)
    min_labeled_predictions: int = Field(default=50, ge=1)
    
    # Retention
    metrics_retention_days: int = Field(default=30, ge=1)
    backup_retention_count: int = Field(default=5, ge=1)


class TrainingConfig(BaseModel):
    """Configuraci√≥n de entrenamiento"""
    test_size: float = Field(default=0.2, ge=0.1, le=0.5, description="Tama√±o del conjunto de test")
    random_seed: int = Field(default=42, ge=0, description="Seed para reproducibilidad")
    n_trials_default: int = Field(default=20, ge=1, description="Trials de Optuna (default)")
    n_trials_ci: int = Field(default=10, ge=1, description="Trials de Optuna (CI/CD)")
    cv_folds_default: int = Field(default=3, ge=2, description="Folds de CV (default)")
    cv_folds_ci: int = Field(default=2, ge=2, description="Folds de CV (CI/CD)")
    max_features: int = Field(default=5000, ge=100, description="Features m√°ximas TF-IDF")
    
    @validator('test_size')
    def validate_test_size(cls, v):
        if not 0.1 <= v <= 0.5:
            raise ValueError(f"test_size debe estar entre 0.1 y 0.5, recibido: {v}")
        return v


class TimeoutsConfig(BaseModel):
    """Configuraci√≥n de timeouts"""
    api_health_check: int = Field(default=5, ge=1, description="Timeout health check (segundos)")
    api_drift_check: int = Field(default=10, ge=1, description="Timeout drift check (segundos)")
    training_max: int = Field(default=3600, ge=60, description="Timeout m√°ximo entrenamiento (segundos)")
    dvc_operation: int = Field(default=300, ge=10, description="Timeout operaciones DVC (segundos)")
    
    @validator('training_max')
    def validate_training_max(cls, v):
        if v > 7200:  # 2 horas
            logger.warning(f"training_max es muy alto: {v}s (>2 horas), considera reducirlo")
        return v


class APIConfig(BaseModel):
    """Configuraci√≥n de API"""
    host: str = Field(default="0.0.0.0", description="Host de la API")
    port: int = Field(default=8000, ge=1024, le=65535, description="Puerto de la API")
    log_dir: str = Field(default="monitoring/logs", description="Directorio de logs")
    
    @validator('port')
    def validate_port(cls, v):
        if v < 1024 or v > 65535:
            raise ValueError(f"port debe estar entre 1024 y 65535, recibido: {v}")
        return v


class DatabaseConfig(BaseModel):
    """Configuraci√≥n de base de datos"""
    table_name: str = Field(default="tickets_fiducia", description="Nombre de la tabla")
    auto_update: bool = Field(default=True, description="Actualizar BD autom√°ticamente al predecir")
    
    @validator('table_name')
    def validate_table_name(cls, v):
        if not v or len(v.strip()) == 0:
            raise ValueError("table_name no puede estar vac√≠o")
        # Validar caracteres v√°lidos para nombre de tabla SQL
        if not re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', v):
            raise ValueError(f"table_name inv√°lido: {v}. Debe contener solo letras, n√∫meros y guiones bajos")
        return v.strip()


class Config(BaseModel):
    """Configuraci√≥n completa del sistema"""
    data: DataConfig
    mlflow_tracking: MLflowTrackingConfig
    preprocessing: PreprocessingConfig
    monitoring: MonitoringConfig
    thresholds: ThresholdsConfig
    training: TrainingConfig
    timeouts: TimeoutsConfig
    api: APIConfig
    database: DatabaseConfig
    
    class Config:
        """Configuraci√≥n de Pydantic"""
        validate_assignment = True  # Validar tambi√©n al asignar valores
        extra = 'forbid'  # No permitir campos extras no definidos


# ============================================================================
# FUNCIONES DE UTILIDAD
# ============================================================================

def validate_config(config_dict: dict) -> Config:
    """
    Valida un diccionario de configuraci√≥n contra el schema.
    
    Args:
        config_dict: Diccionario con la configuraci√≥n
        
    Returns:
        Objeto Config validado
        
    Raises:
        ValidationError: Si la configuraci√≥n es inv√°lida
    """
    try:
        config = Config(**config_dict)
        logger.info("‚úÖ Configuraci√≥n validada exitosamente")
        return config
    except ValidationError as e:
        logger.error("‚ùå Error en validaci√≥n de configuraci√≥n:")
        for error in e.errors():
            field = ' ‚Üí '.join(str(x) for x in error['loc'])
            message = error['msg']
            value = error.get('input', 'N/A')
            logger.error(f"   Campo: {field}")
            logger.error(f"   Error: {message}")
            logger.error(f"   Valor: {value}")
        raise


def print_config_summary(config: Config):
    """
    Imprime un resumen de la configuraci√≥n validada.
    
    Args:
        config: Objeto Config validado
    """
    print("=" * 80)
    print("CONFIGURACI√ìN VALIDADA")
    print("=" * 80)
    print(f"\nüìä Datos:")
    print(f"   Dataset: {config.data.dataset_name}")
    print(f"   Path: {config.data.raw_path}")
    print(f"   Target: {config.data.target_col}")
    
    print(f"\nüî¨ Entrenamiento:")
    print(f"   Test size: {config.training.test_size}")
    print(f"   Random seed: {config.training.random_seed}")
    print(f"   Optuna trials: {config.training.n_trials_default}")
    print(f"   CV folds: {config.training.cv_folds_default}")
    
    print(f"\n‚ö†Ô∏è  Monitoreo:")
    print(f"   Drift threshold: {config.monitoring.drift_threshold}")
    print(f"   Performance drop: {config.monitoring.performance_drop_threshold}")
    print(f"   Min improvement: {config.monitoring.min_improvement_for_deploy}")
    
    print(f"\nüåê API:")
    print(f"   Host: {config.api.host}")
    print(f"   Port: {config.api.port}")
    
    print(f"\nüóÑÔ∏è  Base de Datos:")
    print(f"   Tabla: {config.database.table_name}")
    print(f"   Auto-update: {config.database.auto_update}")
    
    print("=" * 80)


# ============================================================================
# TESTING
# ============================================================================

if __name__ == "__main__":
    import yaml
    from pathlib import Path
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    print("üß™ Testing validaci√≥n de configuraci√≥n\n")
    
    # Cargar config.yaml
    config_path = Path(__file__).parent.parent / "config.yaml"
    
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            config_dict = yaml.safe_load(f)
        
        try:
            config = validate_config(config_dict)
            print_config_summary(config)
            print("\n‚úÖ Todas las validaciones pasaron correctamente")
        except ValidationError:
            print("\n‚ùå Errores en la configuraci√≥n")
    else:
        print(f"‚ùå No se encontr√≥ {config_path}")

