# ğŸ« Sistema de ClasificaciÃ³n de Tickets - MLOps

Sistema completo de MLOps para clasificaciÃ³n automÃ¡tica de tickets de soporte con monitoreo, detecciÃ³n de drift y reentrenamiento automÃ¡tico.

## ğŸ“‹ CaracterÃ­sticas

- âœ… **Preprocesamiento robusto** de texto en espaÃ±ol
- âœ… **Entrenamiento automÃ¡tico** de 7 modelos con optimizaciÃ³n de hiperparÃ¡metros (Optuna)
- âœ… **Tracking de experimentos** con MLflow
- âœ… **Versionamiento de modelos** con DVC y S3
- âœ… **API de inferencia** con FastAPI
- âœ… **Monitoreo en tiempo real** de predicciones
- âœ… **DetecciÃ³n automÃ¡tica de drift** (data drift y concept drift)
- âœ… **Reentrenamiento automÃ¡tico** cuando se detectan problemas
- âœ… **Deploy automÃ¡tico** del mejor modelo
- âœ… **CI/CD completo** con GitHub Actions

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Datos (S3)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preprocesamientoâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Entrenamiento  â”‚â”€â”€â”€â”€â”€â–¶â”‚    MLflow     â”‚
â”‚   (7 modelos)    â”‚      â”‚  Tracking     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mejor Modelo   â”‚â”€â”€â”€â”€â”€â–¶â”‚  DVC + S3    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Inference  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Monitoreo     â”‚â”€â”€â”€â”€â”€â–¶â”‚  Drift Det.  â”‚
â”‚   (Logs)        â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
         â”‚                      â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              â”‚ Â¿Drift?       â”‚
         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Apache Airflow    â”‚
         â”‚   OrquestaciÃ³n    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Reentrenamiento  â”‚
         â”‚   AutomÃ¡tico     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estructura del Proyecto

```
ticket-classifier-mlops/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ inference.py          # API FastAPI para predicciones
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_model.py        # Script de entrenamiento
â”‚   â”œâ”€â”€ monitor_and_retrain.py # Monitoreo y reentrenamiento automÃ¡tico
â”‚   â””â”€â”€ deploy_model.py       # Script de deploy
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ preprocessing_data.py # Preprocesamiento de texto
â”‚   â””â”€â”€ monitoring.py         # Sistema de monitoreo y drift detection
â”œâ”€â”€ data-tickets-train/
â”‚   â””â”€â”€ dataset_tickets.csv   # Dataset de entrenamiento
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.pkl        # Mejor modelo entrenado
â”‚   â””â”€â”€ best_model_metadata.json
â”œâ”€â”€ monitoring/
â”‚   â””â”€â”€ logs/                 # Logs de predicciones
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ train_model.yml   # CI/CD para entrenamiento
â”‚       â””â”€â”€ monitor_and_retrain.yml # CI/CD para monitoreo
â”œâ”€â”€ config.yaml               # ConfiguraciÃ³n del proyecto
â””â”€â”€ requirements.txt          # Dependencias
```

## ğŸš€ Inicio RÃ¡pido

### OpciÃ³n 1: Setup AutomÃ¡tico (Recomendado)

```bash
# Clonar repositorio
git clone <repo-url>
cd ticket-classifier-mlops

# Ejecutar script de setup
./setup.sh
```

### OpciÃ³n 2: Setup Manual

```bash
# Clonar repositorio
git clone <repo-url>
cd ticket-classifier-mlops

# Crear entorno virtual
python3.9 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias (versiones fijas para reproducibilidad)
pip install --upgrade pip
pip install -r requirements-lock.txt

# Descargar recursos NLTK
python -c "import nltk; nltk.download('punkt'); nltk.download('punkt_tab'); nltk.download('stopwords')"
```

**ğŸ“š Ver `SETUP.md` para guÃ­a completa de setup y reproducibilidad.**

### 2. Configurar DVC y S3

```bash
# Configurar DVC (si aÃºn no estÃ¡ configurado)
dvc remote add -d s3remote s3://tu-bucket/dvc-storage
dvc remote modify s3remote endpointurl https://s3.amazonaws.com

# Pull de datos y modelo
dvc pull
```

### 3. Entrenar Modelo

```bash
# Entrenar modelo localmente
python scripts/train_model.py
```

### 4. Iniciar API de Inferencia

```bash
# Iniciar API
python api/inference.py

# O con uvicorn
uvicorn api.inference:app --host 0.0.0.0 --port 8000
```

La API estarÃ¡ disponible en `http://localhost:8000`

### 5. Usar la API

```python
import requests

# PredicciÃ³n individual
response = requests.post("http://localhost:8000/predict", json={
    "short_description": "Tengo un problema con mi cuenta",
    "close_notes": "El cliente reporta error al iniciar sesiÃ³n"
})

result = response.json()
print(f"PredicciÃ³n: {result['prediction']}")
print(f"Probabilidad: {result['probability']:.4f}")
```

## ğŸ“Š Monitoreo y Drift Detection

### Sistema de Monitoreo

El sistema monitorea automÃ¡ticamente:

1. **Data Drift**: Cambios en la distribuciÃ³n de datos de entrada
   - DistribuciÃ³n de longitud de texto
   - DistribuciÃ³n de clases
   - Cambios en vocabulario

2. **Concept Drift**: DegradaciÃ³n de performance del modelo
   - Accuracy, F1-Score, Precision, Recall
   - Confianza en predicciones

### Ejecutar Monitoreo Manualmente

```bash
# Verificar drift y reentrenar si es necesario
python scripts/monitor_and_retrain.py
```

### Endpoints de Monitoreo

```bash
# Verificar drift
curl http://localhost:8000/monitoring/drift

# Obtener mÃ©tricas
curl http://localhost:8000/monitoring/metrics

# Guardar mÃ©tricas diarias
curl -X POST http://localhost:8000/monitoring/save-metrics
```

## ğŸ”„ Reentrenamiento AutomÃ¡tico

El sistema reentrena automÃ¡ticamente cuando:

1. **Data Drift detectado**: Score de drift > 0.5
2. **Performance degradada**: F1-Score baja > 5% vs modelo entrenado
3. **Baja confianza**: > 30% de predicciones con confianza < 0.5

### Flujo de Reentrenamiento

1. Monitoreo detecta problema
2. Se dispara reentrenamiento automÃ¡tico
3. Se entrena nuevo modelo con todos los algoritmos
4. Se compara con modelo actual
5. Si el nuevo es mejor (>1% mejora), se hace deploy automÃ¡tico

### Configurar Reentrenamiento AutomÃ¡tico

El workflow de GitHub Actions ejecuta monitoreo cada 6 horas:

```yaml
# .github/workflows/monitor_and_retrain.yml
schedule:
  - cron: '0 */6 * * *'  # Cada 6 horas
```

TambiÃ©n se puede ejecutar manualmente desde GitHub Actions.

## ğŸš¢ Deploy

### Deploy AutomÃ¡tico

El deploy se ejecuta automÃ¡ticamente despuÃ©s de reentrenamiento exitoso:

```bash
# Deploy manual
python scripts/deploy_model.py
```

### Deploy en ProducciÃ³n

Para producciÃ³n, actualizar `scripts/deploy_model.py` para:

1. Copiar modelo a directorio de producciÃ³n
2. Reiniciar servicio API
3. Actualizar MLflow Model Registry
4. Enviar notificaciones (Slack, Email, etc.)

## âš™ï¸ ConfiguraciÃ³n

Editar `config.yaml` para personalizar:

```yaml
monitoring:
  drift_threshold: 0.05
  drift_score_threshold: 0.5
  performance_drop_threshold: 0.05
  min_improvement_for_deploy: 0.01
```

## ğŸ“ˆ Modelos Disponibles

El sistema entrena y compara 7 modelos:

1. Logistic Regression
2. Random Forest
3. XGBoost
4. SVM
5. LightGBM
6. Gradient Boosting â­ (actualmente el mejor)
7. Extra Trees

## ğŸ” Endpoints de la API

### `GET /`
Health check bÃ¡sico

### `GET /health`
Health check detallado

### `POST /predict`
PredicciÃ³n individual
```json
{
  "short_description": "texto",
  "close_notes": "texto opcional",
  "true_label": "label opcional (para evaluaciÃ³n)"
}
```

### `POST /predict/batch`
PredicciÃ³n en batch (mÃºltiples tickets)

### `GET /monitoring/drift`
Verifica drift en datos recientes

### `GET /monitoring/metrics`
Obtiene mÃ©tricas de monitoreo

### `POST /monitoring/save-metrics`
Guarda mÃ©tricas diarias

## ğŸ§ª Testing

```bash
# Test de la API
curl http://localhost:8000/health

# Test de predicciÃ³n
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "short_description": "Problema con login",
    "close_notes": "Usuario no puede acceder"
  }'
```

## ğŸ“ Logs y Monitoreo

Los logs de predicciones se guardan en:
- `monitoring/logs/predictions.jsonl` - Predicciones individuales
- `monitoring/logs/daily_metrics.json` - MÃ©tricas diarias agregadas

## ğŸ” Variables de Entorno

```bash
# API
export API_URL=http://localhost:8000

# Monitoreo
export DRIFT_THRESHOLD=0.5
export MIN_PREDICTIONS_FOR_DRIFT=100
export PERFORMANCE_DROP_THRESHOLD=0.05

# AWS (para DVC)
export AWS_ACCESS_KEY_ID=tu_key
export AWS_SECRET_ACCESS_KEY=tu_secret
```

## ğŸ› Troubleshooting

### API no inicia
- Verificar que el modelo existe: `models/best_model.pkl`
- Verificar que las dependencias estÃ¡n instaladas

### Drift detection no funciona
- Verificar que hay suficientes predicciones (>100)
- Verificar que la API estÃ¡ corriendo y accesible

### Reentrenamiento falla
- Verificar que hay datos en `data-tickets-train/dataset_tickets.csv`
- Verificar permisos de AWS para DVC push

## ğŸš€ OrquestaciÃ³n con Apache Airflow

El sistema incluye orquestaciÃ³n completa con Apache Airflow:

### DAGs Disponibles

1. **`mlops_ticket_classifier_pipeline`** - Pipeline completo E2E
   - Monitoreo â†’ Reentrenamiento â†’ Deploy
   - Schedule: Cada 6 horas

2. **`train_model_manual`** - Entrenamiento manual
   - Ãštil para reentrenamientos forzados

3. **`monitor_only`** - Solo monitoreo
   - Schedule: Cada hora

### Inicio RÃ¡pido con Airflow

```bash
cd airflow
docker-compose up -d
```

Accede a la UI en: http://localhost:8080

Ver documentaciÃ³n completa en: `airflow/README.md`

## ğŸ“š PrÃ³ximos Pasos

- [x] âœ… OrquestaciÃ³n con Apache Airflow
- [ ] Implementar notificaciones (Slack/Email)
- [ ] Dashboard de monitoreo (Grafana/Dash)
- [ ] A/B testing de modelos
- [ ] Feature store para datos
- [ ] Model explainability (SHAP)

## ğŸ“„ Licencia

[Tu licencia aquÃ­]

## ğŸ‘¥ Autores

Sistema MLOps - 2024

