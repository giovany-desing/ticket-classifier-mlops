name: ü§ñ Train ML Model

on:
  # Ejecutar manualmente desde GitHub UI
  workflow_dispatch:
    inputs:
      description:
        description: 'Descripci√≥n del entrenamiento'
        required: false
        default: 'Entrenamiento manual'
  
  # Ejecutar cuando se actualiza el dataset o el c√≥digo de entrenamiento
  push:
    branches:
      - main
      - develop
    paths:
      - 'data-tickets-train/**'
      - 'scripts/train_model.py'
      - 'utils/preprocessing_data.py'
      - 'config.yaml'
      - 'requirements.txt'

  # Programar entrenamiento autom√°tico (opcional)
  # schedule:
  #   - cron: '0 0 1 * *'  # Primer d√≠a de cada mes a medianoche UTC

env:
  PYTHON_VERSION: '3.9'
  AWS_REGION: us-east-1

jobs:
  train:
    name: üöÄ Train and Optimize Models
    runs-on: ubuntu-latest
    timeout-minutes: 60  # 1 hora m√°ximo (ajusta seg√∫n necesites)
    
    steps:
      # ======================================================================
      # SETUP
      # ======================================================================
      
      - name: üì• Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Para tener todo el historial de git
      
      - name: üêç Setup Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip list  # Para debugging
      
      - name: üìö Download NLTK data
        run: |
          python -c "
          import nltk
          print('Descargando recursos NLTK...')
          nltk.download('punkt', quiet=True)
          nltk.download('punkt_tab', quiet=True)
          nltk.download('stopwords', quiet=True)
          print('‚úì Recursos NLTK descargados')
          "
      
      # ======================================================================
      # DVC SETUP
      # ======================================================================
      
      - name: üóÑÔ∏è Configure DVC
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
        run: |
          echo "üìã Configurando DVC..."
          dvc version
          dvc remote list
          
          echo "üì• Descargando dataset desde S3..."
          dvc pull data-tickets-train/dataset_tickets.csv.dvc
          
          echo "‚úì Dataset descargado"
          ls -lh data-tickets-train/
      
      - name: üîç Verify dataset
        run: |
          python << 'EOF'
          import pandas as pd
          from pathlib import Path
          
          dataset_path = Path('data-tickets-train/dataset_tickets.csv')
          
          if not dataset_path.exists():
              raise FileNotFoundError(f"Dataset no encontrado: {dataset_path}")
          
          df = pd.read_csv(dataset_path)
          
          print(f"‚úì Dataset cargado correctamente")
          print(f"  Filas: {len(df):,}")
          print(f"  Columnas: {df.columns.tolist()}")
          print(f"  Tama√±o: {dataset_path.stat().st_size / (1024*1024):.2f} MB")
          
          # Verificar columnas requeridas
          required = ['short_description', 'close_notes', 'etiqueta']
          missing = [col for col in required if col not in df.columns]
          
          if missing:
              raise ValueError(f"Columnas faltantes: {missing}")
          
          print(f"‚úì Todas las columnas requeridas presentes")
          EOF
      
      # ======================================================================
      # TRAINING
      # ======================================================================
      
      - name: üöÄ Train models
        env:
          CI: true  # Variable para que el script detecte CI
          GITHUB_ACTIONS: true
        run: |
          echo "üéØ Iniciando entrenamiento..."
          python scripts/train_model.py
          
          echo "‚úì Entrenamiento completado"
      
      # ======================================================================
      # SAVE ARTIFACTS
      # ======================================================================
      
      - name: üíæ Upload trained model
        uses: actions/upload-artifact@v3
        if: success()
        with:
          name: trained-model-${{ github.sha }}
          path: |
            models/best_model.pkl
            models/best_model_metadata.json
          retention-days: 90
      
      - name: üìä Upload MLflow artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: mlflow-runs-${{ github.sha }}
          path: mlruns/
          retention-days: 30
      
      # ======================================================================
      # UPLOAD TO S3 (OPCIONAL)
      # ======================================================================
      
      - name: ‚òÅÔ∏è Upload model to S3
        if: success() && github.ref == 'refs/heads/main'
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
        run: |
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          BUCKET_NAME="${{ secrets.S3_MODELS_BUCKET }}"
          
          if [ -z "$BUCKET_NAME" ]; then
            echo "‚ö†Ô∏è  S3_MODELS_BUCKET no configurado, saltando upload a S3"
            exit 0
          fi
          
          echo "‚òÅÔ∏è  Subiendo modelo a S3..."
          
          # Subir con timestamp
          aws s3 cp models/best_model.pkl \
            s3://${BUCKET_NAME}/models/best_model_${TIMESTAMP}.pkl
          
          aws s3 cp models/best_model_metadata.json \
            s3://${BUCKET_NAME}/models/best_model_metadata_${TIMESTAMP}.json
          
          # Subir como "latest" (sobrescribe el anterior)
          aws s3 cp models/best_model.pkl \
            s3://${BUCKET_NAME}/models/latest/best_model.pkl
          
          aws s3 cp models/best_model_metadata.json \
            s3://${BUCKET_NAME}/models/latest/best_model_metadata.json
          
          echo "‚úì Modelo subido a S3"
      
      # ======================================================================
      # SUMMARY
      # ======================================================================
      
      - name: üìã Generate summary
        if: always()
        run: |
          echo "# üéØ Training Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "models/best_model_metadata.json" ]; then
            echo "## ‚úÖ Training Completed Successfully" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            python << 'EOF' >> $GITHUB_STEP_SUMMARY
          import json
          
          with open('models/best_model_metadata.json', 'r') as f:
              metadata = json.load(f)
          
          print(f"**Best Model:** {metadata['model_name']}")
          print(f"**F1-Score:** {metadata['f1_score']:.4f}")
          print(f"**Timestamp:** {metadata['timestamp']}")
          print(f"**Environment:** {metadata['environment']}")
          print("")
          print("### üìä All Models Comparison")
          print("")
          print("| Model | Accuracy | F1-Score | Precision | Recall |")
          print("|-------|----------|----------|-----------|--------|")
          
          results = sorted(
              metadata['all_results'].items(),
              key=lambda x: x[1]['f1_score'],
              reverse=True
          )
          
          for nombre, metricas in results:
              print(f"| {nombre} | {metricas['accuracy']:.4f} | {metricas['f1_score']:.4f} | {metricas['precision']:.4f} | {metricas['recall']:.4f} |")
          EOF
          else
            echo "## ‚ùå Training Failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check the logs for details." >> $GITHUB_STEP_SUMMARY
          fi
      
      # ======================================================================
      # NOTIFICATIONS (OPCIONAL)
      # ======================================================================
      
      - name: üìß Notify on success
        if: success()
        run: |
          echo "‚úÖ Entrenamiento completado exitosamente"
          # Aqu√≠ puedes agregar notificaciones a Slack, Discord, email, etc.
      
      - name: üö® Notify on failure
        if: failure()
        run: |
          echo "‚ùå Entrenamiento fall√≥"
          # Notificaci√≥n de error
```
