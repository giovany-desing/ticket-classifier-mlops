name: ü§ñ Train ML Model with DVC

on:
  workflow_dispatch:
    inputs:
      description:
        description: 'Descripci√≥n del entrenamiento'
        required: false
        default: 'Entrenamiento manual'
  
  push:
    branches:
      - main
      - develop
    paths:
      - 'data-tickets-train/**'
      - 'scripts/train_model.py'
      - 'utils/preprocessing_data.py'
      - 'config.yaml'
      - 'requirements.txt'

env:
  PYTHON_VERSION: '3.9'
  AWS_REGION: us-east-1

jobs:
  train:
    name: üöÄ Train and Version Models
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
      # ======================================================================
      # SETUP
      # ======================================================================
      
      - name: üì• Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: üêç Setup Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip list
      
      - name: üìö Download NLTK data
        run: |
          python -c "
          import nltk
          print('Descargando recursos NLTK...')
          nltk.download('punkt', quiet=True)
          nltk.download('punkt_tab', quiet=True)
          nltk.download('stopwords', quiet=True)
          print('‚úì Recursos NLTK descargados')
          "
      
      # ======================================================================
      # DVC SETUP
      # ======================================================================
      
      - name: üóÑÔ∏è Configure DVC
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
        run: |
          echo "üìã Configurando DVC..."
          dvc version
          dvc remote list
          
          echo "üì• Descargando dataset desde S3..."
          dvc pull data-tickets-train/dataset_tickets.csv.dvc
          
          echo "‚úì Dataset descargado"
          ls -lh data-tickets-train/
      
      - name: üîç Verify dataset
        run: |
          python << 'EOF'
          import pandas as pd
          from pathlib import Path
          
          dataset_path = Path('data-tickets-train/dataset_tickets.csv')
          
          if not dataset_path.exists():
              raise FileNotFoundError(f"Dataset no encontrado: {dataset_path}")
          
          df = pd.read_csv(dataset_path)
          
          print(f"‚úì Dataset cargado correctamente")
          print(f"  Filas: {len(df):,}")
          print(f"  Columnas: {df.columns.tolist()}")
          print(f"  Tama√±o: {dataset_path.stat().st_size / (1024*1024):.2f} MB")
          
          required = ['short_description', 'close_notes', 'etiqueta']
          missing = [col for col in required if col not in df.columns]
          
          if missing:
              raise ValueError(f"Columnas faltantes: {missing}")
          
          print(f"‚úì Todas las columnas requeridas presentes")
          EOF
      
      # ======================================================================
      # TRAINING
      # ======================================================================
      
      - name: üöÄ Train models
        env:
          CI: true
          GITHUB_ACTIONS: true
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
        run: |
          echo "üéØ Iniciando entrenamiento..."
          python scripts/train_model.py
          echo "‚úì Entrenamiento completado"
      
      # ======================================================================
      # DVC COMMIT & PUSH
      # ======================================================================
      
      - name: üì§ Version model with DVC
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
        run: |
          echo "üìã Versionando modelo con DVC..."
          
          # Verificar que el modelo existe
          if [ ! -f "models/best_model.pkl" ]; then
            echo "‚ùå Modelo no encontrado"
            exit 1
          fi
          
          # Verificar si hay cambios en el modelo
          if [ -f "models/best_model.pkl.dvc" ]; then
            echo "‚úì Modelo ya trackeado, verificando cambios..."
          else
            echo "üÜï Primera vez trackeando modelo..."
          fi
          
          # DVC add (crea o actualiza el .dvc file)
          dvc add models/best_model.pkl
          
          # Push a S3 (el script ya lo hizo, pero por si acaso)
          echo "‚òÅÔ∏è  Verificando push a S3..."
          dvc push models/best_model.pkl.dvc
          
          echo "‚úì Modelo versionado exitosamente"
      
      - name: üìù Commit DVC files to Git
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Agregar archivos DVC y metadata
          git add models/best_model.pkl.dvc models/.gitignore models/best_model_metadata.json
          
          # Commit solo si hay cambios
          if git diff --staged --quiet; then
            echo "‚ÑπÔ∏è  No hay cambios para commitear"
          else
            TIMESTAMP=$(date +'%Y-%m-%d %H:%M:%S')
            git commit -m "ü§ñ Update model: ${TIMESTAMP} [skip ci]"
            git push
            echo "‚úì Cambios pusheados a GitHub"
          fi
      
      # ======================================================================
      # SAVE ARTIFACTS
      # ======================================================================
      
      - name: üíæ Upload artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: training-artifacts-${{ github.sha }}
          path: |
            models/best_model_metadata.json
            models/best_model.pkl.dvc
            mlruns/
          retention-days: 30
      
      # ======================================================================
      # SUMMARY
      # ======================================================================
      
      - name: üìã Generate summary
        if: always()
        run: |
          echo "# üéØ Training Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "models/best_model_metadata.json" ]; then
            echo "## ‚úÖ Training & Versioning Completed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            python << 'EOF' >> $GITHUB_STEP_SUMMARY
          import json
          from pathlib import Path
          
          with open('models/best_model_metadata.json', 'r') as f:
              metadata = json.load(f)
          
          print(f"**Best Model:** {metadata['model_name']}")
          print(f"**F1-Score:** {metadata['f1_score']:.4f}")
          print(f"**Timestamp:** {metadata['timestamp']}")
          print(f"**Environment:** {metadata['environment']}")
          
          # Verificar DVC
          dvc_file = Path('models/best_model.pkl.dvc')
          if dvc_file.exists():
              print(f"**DVC Status:** ‚úÖ Versioned")
              print(f"**DVC File:** `models/best_model.pkl.dvc`")
          else:
              print(f"**DVC Status:** ‚ö†Ô∏è Not versioned")
          
          print("")
          print("### üìä All Models Comparison")
          print("")
          print("| Model | Accuracy | F1-Score | Precision | Recall |")
          print("|-------|----------|----------|-----------|--------|")
          
          results = sorted(
              metadata['all_results'].items(),
              key=lambda x: x[1]['f1_score'],
              reverse=True
          )
          
          for rank, (nombre, metricas) in enumerate(results, 1):
              emoji = "ü•á" if rank == 1 else "ü•à" if rank == 2 else "ü•â" if rank == 3 else ""
              print(f"| {emoji} {nombre} | {metricas['accuracy']:.4f} | {metricas['f1_score']:.4f} | {metricas['precision']:.4f} | {metricas['recall']:.4f} |")
          
          print("")
          print("### üóÑÔ∏è DVC Commands")
          print("")
          print("To pull this model locally:")
          print("```bash")
          print("dvc pull models/best_model.pkl.dvc")
          print("```")
          
          print("")
          print("To view model history:")
          print("```bash")
          print("git log --oneline -- models/best_model.pkl.dvc")
          print("```")
          EOF
          else
            echo "## ‚ùå Training Failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Check the logs for details." >> $GITHUB_STEP_SUMMARY
          fi
      
      # ======================================================================
      # NOTIFICATIONS
      # ======================================================================
      
      - name: üìß Notify on success
        if: success()
        run: |
          echo "‚úÖ Modelo entrenado y versionado exitosamente"
      
      - name: üö® Notify on failure
        if: failure()
        run: |
          echo "‚ùå Proceso fall√≥. Revisar logs."